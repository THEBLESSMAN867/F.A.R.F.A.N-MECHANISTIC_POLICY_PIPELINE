"""
Enhanced Contract System with Pydantic - Production Grade
==========================================================

Strict contract definitions with cryptographic verification, deterministic
execution guarantees, and comprehensive validation.

Features:
- Static typing with Pydantic BaseModel
- Schema versioning for backward compatibility
- Cryptographic content digests (SHA-256)
- UTC timestamps (ISO-8601)
- Domain-specific exceptions
- Structured JSON logging
- Flow compatibility validation

Author: Policy Analytics Research Unit
Version: 2.0.0
License: Proprietary
"""

from __future__ import annotations

import hashlib
import json
import logging
import uuid
from datetime import datetime, timezone
from typing import Any

from pydantic import BaseModel, ConfigDict, Field, field_validator
from farfan_pipeline.core.parameters import ParameterLoaderV2
from farfan_pipeline.core.calibration.decorators import calibrated_method

# ============================================================================
# DOMAIN-SPECIFIC EXCEPTIONS
# ============================================================================

class ContractValidationError(Exception):
    """Raised when contract validation fails."""

    def __init__(self, message: str, field: str | None = None, event_id: str | None = None) -> None:
        self.field = field
        self.event_id = event_id or str(uuid.uuid4())
        super().__init__(f"[{self.event_id}] {message}")


class DataIntegrityError(Exception):
    """Raised when data integrity checks fail (e.g., hash mismatch)."""

    def __init__(self, message: str, expected: str | None = None, got: str | None = None, event_id: str | None = None) -> None:
        self.expected = expected
        self.got = got
        self.event_id = event_id or str(uuid.uuid4())
        super().__init__(f"[{self.event_id}] {message}")


class SystemConfigError(Exception):
    """Raised when system configuration is invalid."""

    def __init__(self, message: str, config_key: str | None = None, event_id: str | None = None) -> None:
        self.config_key = config_key
        self.event_id = event_id or str(uuid.uuid4())
        super().__init__(f"[{self.event_id}] {message}")


class FlowCompatibilityError(Exception):
    """Raised when data flow between components is incompatible."""

    def __init__(self, message: str, producer: str | None = None, consumer: str | None = None, event_id: str | None = None) -> None:
        self.producer = producer
        self.consumer = consumer
        self.event_id = event_id or str(uuid.uuid4())
        super().__init__(f"[{self.event_id}] {message}")


# ============================================================================
# UTILITY FUNCTIONS FOR DETERMINISM AND VALIDATION
# ============================================================================

def compute_content_digest(content: str | bytes | dict[str, Any]) -> str:
    """
    Compute SHA-256 digest of content in a deterministic way.

    Args:
        content: String, bytes, or dict to hash

    Returns:
        Hexadecimal SHA-256 digest

    Examples:
        >>> digest = compute_content_digest("test")
        >>> len(digest)
        64
        >>> digest == compute_content_digest("test")  # Deterministic
        True
    """
    if isinstance(content, dict):
        # Sort keys for deterministic JSON
        content_str = json.dumps(content, sort_keys=True, ensure_ascii=True)
        content_bytes = content_str.encode('utf-8')
    elif isinstance(content, str):
        content_bytes = content.encode('utf-8')
    elif isinstance(content, bytes):
        content_bytes = content
    else:
        raise ContractValidationError(
            f"Cannot compute digest for type {type(content).__name__}",
            field="content"
        )

    return hashlib.sha256(content_bytes).hexdigest()


def utc_now_iso() -> str:
    """
    Get current UTC timestamp in ISO-8601 format.

    Returns:
        ISO-8601 timestamp string (UTC timezone)

    Examples:
        >>> ts = utc_now_iso()
        >>> 'T' in ts and 'Z' in ts
        True
    """
    return datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')


# ============================================================================
# BASE CONTRACT MODEL
# ============================================================================

class BaseContract(BaseModel):
    """
    Base contract model with common fields for all contracts.

    All contracts must include:
    - schema_version: Semantic version for contract evolution
    - timestamp_utc: ISO-8601 UTC timestamp
    - correlation_id: UUID for request tracing
    """

    model_config = ConfigDict(
        frozen=True,  # Immutable for safety
        extra='forbid',  # Reject unknown fields
        validate_assignment=True,
        str_strip_whitespace=True,
    )

    schema_version: str = Field(
        default="2.ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L151_19", 0.0)",
        description="Contract schema version (semantic versioning)",
        pattern=r"^\d+\.\d+\.\d+$"
    )

    timestamp_utc: str = Field(
        default_factory=utc_now_iso,
        description="UTC timestamp in ISO-8601 format"
    )

    correlation_id: str = Field(
        default_factory=lambda: str(uuid.uuid4()),
        description="UUID for request correlation and tracing"
    )

    @field_validator('timestamp_utc')
    @classmethod
    def validate_timestamp(cls, v: str) -> str:
        """Validate timestamp is ISO-8601 format and UTC."""
        try:
            dt = datetime.fromisoformat(v.replace('Z', '+00:00'))
            # Ensure UTC
            if dt.tzinfo is None or dt.utcoffset() != timezone.utc.utcoffset(None):
                raise ValueError("Timestamp must be UTC")
            return v
        except (ValueError, AttributeError) as e:
            raise ContractValidationError(
                f"Invalid ISO-8601 timestamp: {v}",
                field="timestamp_utc"
            ) from e


# ============================================================================
# DOCUMENT CONTRACTS - V2
# ============================================================================

class DocumentMetadataV2(BaseContract):
    """
    Enhanced document metadata with cryptographic verification.

    Attributes:
        file_path: Absolute path to document
        file_name: Document filename
        num_pages: Number of pages
        file_size_bytes: File size in bytes
        content_digest: SHA-256 hash of file content
        policy_unit_id: Unique identifier for policy unit
        encoding: Character encoding (default: utf-8)
    """

    file_path: str = Field(..., description="Absolute path to document")
    file_name: str = Field(..., description="Document filename", min_length=1)
    num_pages: int = Field(..., description="Number of pages", ge=1)
    file_size_bytes: int = Field(..., description="File size in bytes", ge=0)
    content_digest: str = Field(..., description="SHA-256 hash of content", pattern=r"^[a-f0-9]{64}$")
    policy_unit_id: str = Field(..., description="Unique policy unit identifier")
    encoding: str = Field(default="utf-8", description="Character encoding")

    # Optional metadata
    pdf_metadata: dict[str, Any] | None = Field(default=None, description="PDF metadata dictionary")
    author: str | None = Field(default=None, description="Document author")
    title: str | None = Field(default=None, description="Document title")
    creation_date: str | None = Field(default=None, description="Document creation date")


class ProcessedTextV2(BaseContract):
    """
    Enhanced processed text with input/output validation.

    Attributes:
        raw_text: Original unprocessed text
        normalized_text: Normalized/cleaned text
        language: Detected language code
        input_digest: SHA-256 of raw_text input
        output_digest: SHA-256 of normalized_text output
        policy_unit_id: Policy unit identifier
        processing_latency_ms: Processing time in milliseconds
    """

    raw_text: str = Field(..., description="Original unprocessed text", min_length=1)
    normalized_text: str = Field(..., description="Normalized/cleaned text", min_length=1)
    language: str = Field(..., description="ISO 639-1 language code", pattern=r"^[a-z]{2}$")
    input_digest: str = Field(..., description="SHA-256 of raw_text", pattern=r"^[a-f0-9]{64}$")
    output_digest: str = Field(..., description="SHA-256 of normalized_text", pattern=r"^[a-f0-9]{64}$")
    policy_unit_id: str = Field(..., description="Policy unit identifier")
    processing_latency_ms: float = Field(..., description="Processing latency in ms", ge=ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L236_89", 0.0))

    # Optional fields
    sentences: list[str] | None = Field(default=None, description="Sentence segmentation")
    sections: list[dict[str, Any]] | None = Field(default=None, description="Document sections")
    payload_size_bytes: int | None = Field(default=None, description="Payload size", ge=0)

    @field_validator('input_digest')
    @classmethod
    def validate_input_digest(cls, v: str, info) -> str:
        """Verify input digest matches raw_text if available."""
        # This is validated post-construction
        return v


# ============================================================================
# ANALYSIS CONTRACTS - V2
# ============================================================================

class AnalysisInputV2(BaseContract):
    """
    Enhanced analysis input with cryptographic verification.

    Attributes:
        text: Input text to analyze
        document_id: Unique document identifier
        policy_unit_id: Policy unit identifier
        input_digest: SHA-256 of input text
        payload_size_bytes: Size of input payload
    """

    text: str = Field(..., description="Input text to analyze", min_length=1)
    document_id: str = Field(..., description="Unique document identifier")
    policy_unit_id: str = Field(..., description="Policy unit identifier")
    input_digest: str = Field(
        ...,
        description="SHA-256 hash of input text",
        pattern=r"^[a-f0-9]{64}$"
    )
    payload_size_bytes: int = Field(..., description="Payload size in bytes", ge=0)

    # Optional context
    metadata: dict[str, Any] | None = Field(default=None, description="Additional metadata")
    context: dict[str, Any] | None = Field(default=None, description="Execution context")
    sentences: list[str] | None = Field(default=None, description="Pre-segmented sentences")

    @classmethod
    def create_from_text(
        cls,
        text: str,
        document_id: str,
        policy_unit_id: str,
        **kwargs: Any
    ) -> AnalysisInputV2:
        """
        Factory method to create AnalysisInputV2 with auto-computed digest.

        Args:
            text: Input text
            document_id: Document ID
            policy_unit_id: Policy unit ID
            **kwargs: Additional optional fields

        Returns:
            Validated AnalysisInputV2 instance
        """
        input_digest = compute_content_digest(text)
        payload_size_bytes = len(text.encode('utf-8'))

        return cls(
            text=text,
            document_id=document_id,
            policy_unit_id=policy_unit_id,
            input_digest=input_digest,
            payload_size_bytes=payload_size_bytes,
            **kwargs
        )


class AnalysisOutputV2(BaseContract):
    """
    Enhanced analysis output with confidence bounds and validation.

    Attributes:
        dimension: Analysis dimension
        category: Result category
        confidence: Confidence score [ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L322_38", 0.0), ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L322_43", 1.0)]
        matches: Evidence matches
        output_digest: SHA-256 of output content
        policy_unit_id: Policy unit identifier
        processing_latency_ms: Processing time in milliseconds
    """

    dimension: str = Field(..., description="Analysis dimension", min_length=1)
    category: str = Field(..., description="Result category", min_length=1)
    confidence: float = Field(..., description="Confidence score", ge=ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L331_70", 0.0), le=ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L331_78", 1.0))
    matches: list[str] = Field(..., description="Evidence matches")
    output_digest: str = Field(..., description="SHA-256 of output", pattern=r"^[a-f0-9]{64}$")
    policy_unit_id: str = Field(..., description="Policy unit identifier")
    processing_latency_ms: float = Field(..., description="Processing latency in ms", ge=ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L335_89", 0.0))

    # Optional fields
    positions: list[int] | None = Field(default=None, description="Match positions")
    evidence: list[str] | None = Field(default=None, description="Supporting evidence")
    warnings: list[str] | None = Field(default=None, description="Validation warnings")
    payload_size_bytes: int | None = Field(default=None, description="Output payload size", ge=0)

    @field_validator('confidence')
    @classmethod
    def validate_confidence_numerical_stability(cls, v: float) -> float:
        """Ensure confidence is numerically stable and within bounds."""
        if not (ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L347_16", 0.0) <= v <= ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L347_28", 1.0)):
            raise ContractValidationError(
                f"Confidence must be in [ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L349_41", 0.0), ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.FlowCompatibilityError.__init__", "auto_param_L349_46", 1.0)], got {v}",
                field="confidence"
            )
        # Round to avoid floating point precision issues
        return round(v, 6)


# ============================================================================
# EXECUTION CONTRACTS - V2
# ============================================================================

class ExecutionContextV2(BaseContract):
    """
    Enhanced execution context with full observability.

    Attributes:
        class_name: Executor class name
        method_name: Method being executed
        document_id: Document identifier
        policy_unit_id: Policy unit identifier
        execution_id: Unique execution identifier
        parent_correlation_id: Parent request correlation ID
    """

    class_name: str = Field(..., description="Executor class name", min_length=1)
    method_name: str = Field(..., description="Method being executed", min_length=1)
    document_id: str = Field(..., description="Document identifier")
    policy_unit_id: str = Field(..., description="Policy unit identifier")
    execution_id: str = Field(
        default_factory=lambda: str(uuid.uuid4()),
        description="Unique execution identifier"
    )
    parent_correlation_id: str | None = Field(
        default=None,
        description="Parent correlation ID for nested calls"
    )

    # Optional context
    raw_text: str | None = Field(default=None, description="Raw input text")
    text: str | None = Field(default=None, description="Processed text")
    metadata: dict[str, Any] | None = Field(default=None, description="Metadata")
    tables: dict[str, Any] | None = Field(default=None, description="Extracted tables")
    sentences: list[str] | None = Field(default=None, description="Sentences")


# ============================================================================
# STRUCTURED LOGGING HELPER
# ============================================================================

class StructuredLogger:
    """
    Structured JSON logger for observability.

    Logs include:
    - correlation_id for tracing
    - latencies per operation
    - payload sizes
    - cryptographic fingerprints
    - NO PII
    """

    def __init__(self, name: str) -> None:
        """Initialize logger with name."""
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)

    def log_contract_validation(
        self,
        contract_type: str,
        correlation_id: str,
        success: bool,
        latency_ms: float,
        payload_size_bytes: int = 0,
        content_digest: str | None = None,
        error: str | None = None
    ) -> None:
        """Log contract validation event."""
        log_entry = {
            "event": "contract_validation",
            "contract_type": contract_type,
            "correlation_id": correlation_id,
            "success": success,
            "latency_ms": round(latency_ms, 3),
            "payload_size_bytes": payload_size_bytes,
            "timestamp_utc": utc_now_iso(),
        }

        if content_digest:
            log_entry["content_digest"] = content_digest

        if error:
            log_entry["error"] = error

        self.logger.info(json.dumps(log_entry, sort_keys=True))

    def log_execution(
        self,
        operation: str,
        correlation_id: str,
        success: bool,
        latency_ms: float,
        **kwargs: Any
    ) -> None:
        """Log execution event with additional context."""
        log_entry = {
            "event": "execution",
            "operation": operation,
            "correlation_id": correlation_id,
            "success": success,
            "latency_ms": round(latency_ms, 3),
            "timestamp_utc": utc_now_iso(),
        }
        log_entry.update(kwargs)

        self.logger.info(json.dumps(log_entry, sort_keys=True))


# ============================================================================
# IN-SCRIPT TESTS
# ============================================================================

if __name__ == "__main__":
    import doctest

    # Run doctests
    print("Running doctests...")
    doctest.testmod(verbose=True)

    # Contract validation examples
    print("\n" + "="*60)
    print("Contract Validation Examples")
    print("="*60)

    # Example 1: Document metadata
    print("\n1. DocumentMetadataV2 validation:")
    doc_meta = DocumentMetadataV2(
        file_path="/path/to/document.pdf",
        file_name="document.pdf",
        num_pages=10,
        file_size_bytes=1024000,
        content_digest="a" * 64,  # Valid SHA-256 hex
        policy_unit_id="PDM-001"
    )
    print(f"   ✓ Valid: correlation_id={doc_meta.correlation_id[:8]}...")

    # Example 2: Analysis input with auto-digest
    print("\n2. AnalysisInputV2 with auto-computed digest:")
    analysis_input = AnalysisInputV2.create_from_text(
        text="Sample policy text for analysis",
        document_id="DOC-123",
        policy_unit_id="PDM-001"
    )
    print(f"   ✓ Valid: input_digest={analysis_input.input_digest[:16]}...")
    print(f"   ✓ Payload size: {analysis_input.payload_size_bytes} bytes")

    # Example 3: Analysis output with confidence validation
    print("\n3. AnalysisOutputV2 with confidence bounds:")
    analysis_output = AnalysisOutputV2(
        dimension="Dimension1",
        category="CategoryA",
        confidence=ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.StructuredLogger.__init__", "auto_param_L509_19", 0.85),  # Must be in [ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.StructuredLogger.__init__", "auto_param_L509_40", 0.0), ParameterLoaderV2.get("farfan_core.utils.enhanced_contracts.StructuredLogger.__init__", "auto_param_L509_45", 1.0)]
        matches=["evidence1", "evidence2"],
        output_digest="b" * 64,
        policy_unit_id="PDM-001",
        processing_latency_ms=123.456
    )
    print(f"   ✓ Valid: confidence={analysis_output.confidence}")

    # Example 4: Structured logging
    print("\n4. Structured logging example:")
    logger = StructuredLogger("test_logger")
    logger.log_contract_validation(
        contract_type="AnalysisInputV2",
        correlation_id=analysis_input.correlation_id,
        success=True,
        latency_ms=5.2,
        payload_size_bytes=analysis_input.payload_size_bytes,
        content_digest=analysis_input.input_digest
    )
    print("   ✓ JSON log emitted to logger")

    # Example 5: Exception handling
    print("\n5. Domain-specific exceptions:")
    try:
        raise ContractValidationError("Invalid field", field="test_field")
    except ContractValidationError as e:
        print(f"   ✓ ContractValidationError: {e}")
        print(f"   ✓ Event ID: {e.event_id}")

    print("\n" + "="*60)
    print("All validation examples passed!")
    print("="*60)
