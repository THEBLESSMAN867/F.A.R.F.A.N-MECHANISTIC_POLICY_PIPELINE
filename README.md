# F.A.R.F.A.N: Framework for Advanced Retrieval of Administrativa Narratives

**A Mechanistic Policy Pipeline for Colombian Development Plan Analysis**

**F.A.R.F.A.N** is a sophisticated, evidence-based analysis tool for Colombian municipal development plans. It leverages a deterministic pipeline, cryptographic proofs, and a comprehensive questionnaire to deliver rigorous, reproducible results.

---

## âš¡ Quick Start

```bash
# 1. Install dependencies (one-time setup)
bash install.sh

# 2. Activate environment
source farfan-env/bin/activate

# 3. Run health check
bash comprehensive_health_check.sh

# 4. Execute pipeline on test plan
python scripts/run_policy_pipeline_verified.py \
    --plan data/plans/Plan_1.pdf \
    --artifacts-dir artifacts/plan1
```

**Expected time**: 2-3 minutes for complete analysis

---

## ğŸ“š Documentation

| Document | Purpose | Audience |
|----------|---------|----------|
| **[INSTALLATION_GUIDE.md](INSTALLATION_GUIDE.md)** | Complete installation instructions with troubleshooting | All users |
| **[RUNBOOK.md](RUNBOOK.md)** | Operational runbook with launch, health checks, and commands | Operators, DevOps |
| **[TEST_PLAN.md](TEST_PLAN.md)** | Comprehensive test plan (plan prueba) with 10 test cases | QA, Testers |
| **[OPERATIONAL_GUIDE.md](OPERATIONAL_GUIDE.md)** | User operational guide for analysis workflows | Analysts, Users |
| **[ARCHITECTURE.md](ARCHITECTURE.md)** | System architecture and technical design | Developers, Architects |
| **[DEVELOPER_QUICK_REFERENCE.md](DEVELOPER_QUICK_REFERENCE.md)** | Quick reference for developers | Developers |

---

## ğŸš€ Getting Started

For a complete guide to installation, system activation, and your first analysis, please refer to the **[OPERATIONAL_GUIDE.md](OPERATIONAL_GUIDE.md)**. This is the recommended starting point for all users.

## ğŸ›ï¸ Architecture

For a deep dive into the system's architecture, including the 9-phase pipeline, cross-cut signals, and deterministic protocols, see **[ARCHITECTURE.md](ARCHITECTURE.md)**.

## ğŸ”§ Quick Reference

For a quick reference of the project, see **[DEVELOPER_QUICK_REFERENCE.md](DEVELOPER_QUICK_REFERENCE.md)**.

## ğŸ“¦ Installation

This project requires **Python 3.12** and enforces a strict dependency management system to ensure reproducibility.

### **MANDATORY**: Editable Install

You **MUST** install the package in editable mode before using it:

```bash
# âŒ NEVER DO THIS:
jq '.blocks.micro_questions' data/questionnaire_monolith.json

# âœ… ALWAYS DO THIS:
python3 -c "
from saaaaaa.core.orchestrator.questionnaire import load_questionnaire
q = load_questionnaire()
print(f'Micro questions: {q.micro_question_count}')
print(f'Total questions: {q.total_question_count}')
print(f'SHA256: {q.sha256[:16]}...')
"
```

### Updating the Questionnaire

If you legitimately modify `questionnaire_monolith.json`:

1. **Compute new hash:**
   ```bash
   python3 -c "
   import json, hashlib
   data = json.load(open('data/questionnaire_monolith.json'))
   serialized = json.dumps(data, sort_keys=True, ensure_ascii=True, separators=(',', ':'))
   print(hashlib.sha256(serialized.encode()).hexdigest())
   "
   ```

2. **Update `EXPECTED_HASH` in `src/saaaaaa/core/orchestrator/questionnaire.py`:**
   ```python
   EXPECTED_HASH: Final[str] = "NEW_HASH_HERE"
   ```

3. **Commit both files together:**
   ```bash
   git add data/questionnaire_monolith.json src/saaaaaa/core/orchestrator/questionnaire.py
   git commit -m "Update questionnaire structure (hash verified)"
   ```

### Why This Matters

The questionnaire defines the entire analysis pipeline:
- 300 micro questions organized into 6 dimensions (D1-D6)
- 10 policy areas (PA01-PA10)
- 4 clusters for aggregation
- 2,207+ patterns for text matching
- Expected elements and validation rules

**Any corruption or unintended modification would:**
- âŒ Produce different analysis results (non-deterministic)
- âŒ Break reproducibility of published findings
- âŒ Violate audit trail requirements
- âŒ Compromise scientific integrity

**The hash enforcement prevents all of these.**

### Verification

```bash
# Check questionnaire integrity locally
python3 -c "from saaaaaa.core.orchestrator.questionnaire import load_questionnaire; q = load_questionnaire(); print('âœ… VERIFIED:', q.sha256[:16] + '...')"

# Find any violations in the codebase
grep -r "questionnaire_monolith.json" --include="*.py" . | grep -v "src/saaaaaa/core/orchestrator/questionnaire.py" | grep -v ".github/workflows"
# Should return NOTHING (or fail CI)
```

---

**Technical Implementation:** F.A.R.F.A.N integra 584 mÃ©todos analÃ­ticos distribuidos en 7 productores especializados y 1 agregador, orientado al procesamiento determinista de planes de desarrollo municipales y departamentales en Colombia. La contribuciÃ³n tÃ©cnica principal radica en: (1) un pipeline de ingesta con 9 fases deterministas que garantiza trazabilidad completa desde token hasta coordenadas de pÃ¡gina (provenance_completeness = 1.0), (2) un sistema de seÃ±ales transversales (cross-cut signals) con transporte memory:// y HTTP opcional, incluyendo circuit breakers para resiliencia, (3) un mecanismo de enrutamiento extendido (ArgRouter) con 30+ rutas especiales que elimina caÃ­das silenciosas de parÃ¡metros, y (4) contratos explÃ­citos de entrada/salida con validaciÃ³n en fronteras de proveedor. El sistema procesa 300 preguntas de evaluaciÃ³n organizadas en 6 dimensiones (D1-D6: Insumos, Actividades, Productos, Resultados, Impactos, Causalidad) sobre 10 Ã¡reas de polÃ­tica (P1-P10), generando reportes en tres niveles de agregaciÃ³n: MICRO (respuestas atÃ³micas por pregunta, 150-300 palabras), MESO (anÃ¡lisis de clusters por dimensiÃ³n-Ã¡rea), y MACRO (clasificaciÃ³n y recomendaciones). La arquitectura sigue el patrÃ³n "Chess Strategy": apertura paralela con 7 productores independientes, medio juego de triangulaciÃ³n multi-fuente, y final de sÃ­ntesis doctoral. El alcance excluye procesamiento en tiempo real (modo batch Ãºnicamente), datos personales identificables (PII), y claims de precisiÃ³n absoluta sin intervalos de confianza.

---

## Tabla de Contenidos

1. [IntroducciÃ³n](#1-introducciÃ³n)
2. [MÃ©todos / Arquitectura](#2-mÃ©todos--arquitectura)
   - 2.1. [Pipeline de Procesamiento](#21-pipeline-de-procesamiento)
   - 2.2. [Sistema de Contratos](#22-sistema-de-contratos)
   - 2.3. [SeÃ±ales Transversales](#23-seÃ±ales-transversales-cross-cut-signals)
   - 2.4. [CPPAdapter y Canon Policy Package](#24-cppadapter-y-canon-policy-package)
   - 2.5. [ArgRouter Extendido](#25-argrouter-extendido)
   - 2.6. [ParametrizaciÃ³n en CÃ³digo](#26-parametrizaciÃ³n-en-cÃ³digo)
3. [Resultados / MÃ©tricas Operativas](#3-resultados--mÃ©tricas-operativas)
   - 3.1. [MÃ©tricas de SeÃ±ales](#31-mÃ©tricas-de-seÃ±ales)
   - 3.2. [MÃ©tricas de Proveniencia](#32-mÃ©tricas-de-proveniencia)
   - 3.3. [MÃ©tricas de Enrutamiento](#33-mÃ©tricas-de-enrutamiento)
   - 3.4. [MÃ©tricas de Determinismo](#34-mÃ©tricas-de-determinismo)
   - 3.5. [Cobertura de Tests](#35-cobertura-de-tests)
4. [DiscusiÃ³n](#4-discusiÃ³n)
   - 4.1. [Limitaciones Conocidas](#41-limitaciones-conocidas)
   - 4.2. [Amenazas a la Validez](#42-amenazas-a-la-validez)
   - 4.3. [Planes de MitigaciÃ³n](#43-planes-de-mitigaciÃ³n)
5. [Protocolos de Reproducibilidad](#5-protocolos-de-reproducibilidad)
   - 5.1. [EjecuciÃ³n de Golden Tests](#51-ejecuciÃ³n-de-golden-tests)
   - 5.2. [FijaciÃ³n de Semillas](#52-fijaciÃ³n-de-semillas)
   - 5.3. [VerificaciÃ³n de phase_hash](#53-verificaciÃ³n-de-phase_hash)
6. [Ã‰tica y Privacidad](#6-Ã©tica-y-privacidad)
7. [ApÃ©ndices](#7-apÃ©ndices)
   - A. [Tabla de Configuraciones](#apÃ©ndice-a-tabla-de-configuraciones)
   - B. [Changelog Resumido](#apÃ©ndice-b-changelog-resumido)
   - C. [Matriz de Compatibilidad](#apÃ©ndice-c-matriz-de-compatibilidad)
8. [CÃ³mo Citar este Repositorio](#8-cÃ³mo-citar-este-repositorio)
9. [Licencia](#9-licencia)
10. [Referencias Internas](#10-referencias-internas)

### ğŸ”’ Paranoia Constructiva Import System

This project implements a **deterministic, auditable, and portable** import system:

- âœ… **Safe Imports**: `try_import()` with clear error messages
- âœ… **Lazy Loading**: Heavy dependencies loaded on-demand
- âœ… **Optional Extras**: Install only what you need
- âœ… **Platform Checks**: Verify native libraries and wheels
- âœ… **Zero Shadowing**: No local files shadow stdlib
- âœ… **Zero Cycles**: No circular import patterns

**ğŸ“– Complete documentation:** [docs/IMPORT_SYSTEM.md](docs/IMPORT_SYSTEM.md)

**Install with optional extras:**
```bash
pip install saaaaaa[analytics]    # Polars, PyArrow
pip install saaaaaa[ml]            # Torch, TensorFlow
pip install saaaaaa[nlp]           # Transformers, Spacy
pip install saaaaaa[all]           # Everything
```

**Run equipment checks:**
```bash
make equip              # Verify environment readiness
make audit-imports      # Check import health
```

---

## 1. IntroducciÃ³n

### 1.1. What is F.A.R.F.A.N?

F.A.R.F.A.N (Framework for Advanced Retrieval of Administrativa Narratives) is a mechanistic policy pipeline designed specifically for the rigorous, evidence-based, and comprehensive analysis of Colombian municipal development plans. Development plans are policy agenda-setting instruments that attribute political priority to policy issues for a medium-term period. F.A.R.F.A.N analyzes these plans through the lens of policy causal mechanisms, using the heuristic of the value chainâ€”the formal schema for organizing policy interventions in Colombia.

F.A.R.F.A.N delivers highly elaborate, sophisticated, and robust analysis that would traditionally take an incredible amount of time and result in lower quality when done manually. It provides policy communities and citizens the opportunity to have on hand a comprehensive understanding of development plans.

### 1.2. Planteamiento del Problema

La evaluaciÃ³n ex-ante de planes de desarrollo requiere procesamiento analÃ­tico de documentos semi-estructurados (100-300 pÃ¡ginas) bajo mÃºltiples dimensiones: viabilidad financiera, coherencia lÃ³gica, causalidad explÃ­cita, trazabilidad presupuestal, alineaciÃ³n normativa, y evidencia empÃ­rica. Los enfoques tradicionales presentan tres deficiencias:

1. **PÃ©rdida de Trazabilidad**: ExtracciÃ³n de texto sin mapeo pÃ¡gina-token impide auditorÃ­a de inferencias.
2. **Procesamiento No-Determinista**: Variaciones en chunking semÃ¡ntico y resoluciÃ³n de dependencias producen outputs no reproducibles.
3. **TriangulaciÃ³n Manual**: SÃ­ntesis multi-mÃ©todo requiere integraciÃ³n manual, introduciendo sesgos de confirmaciÃ³n.

### 1.3. Estado del Arte MÃ­nimo

Sistemas previos en evaluaciÃ³n de polÃ­ticas (e.g., anÃ¡lisis ToC con DAG validation, scoring Bayesiano, extracciÃ³n de KPIs) operan de forma aislada. Frameworks de NLP (spaCy, Transformers) proveen extracciÃ³n pero no garantÃ­as de proveniencia. RAG (Retrieval-Augmented Generation) carece de contratos formales para composiciÃ³n multi-mÃ©todo. Import-linter y pycycle abordan higiene de dependencias pero no seÃ±ales transversales runtime.

### 1.4. ContribuciÃ³n y Enfoque

F.A.R.F.A.N integra:

1. **Determinismo de Pipeline**: Pipeline canÃ³nico con postcondiciones verificables; fallo en cualquier fase â†’ ABORT (no degradaciÃ³n gradual).
2. **SeÃ±ales Transversales**: Registro centralizado de patrones, indicadores, umbrales desde cuestionario monolito hacia todos los ejecutores, con transporte memory:// (in-process) o HTTP (con circuit breaker).
3. **Proveniencia Completa**: Cada token â†’ `{page_id, bbox, byte_range, parser_id}` mediante Arrow IPC, permitiendo auditorÃ­a forense.
4. **ArgRouter Extendido**: 30+ rutas especiales eliminan caÃ­das silenciosas de parÃ¡metros (argrouter_coverage = 1.0).
5. **Contratos ExplÃ­citos**: TypedDict con validaciÃ³n en fronteras (orchestrator â†” core), detectando violaciones arquitectÃ³nicas en runtime.

**Racionalidad del Determinismo**: En auditorÃ­a pÃºblica, reproducibilidad byte-a-byte es requisito legal. Aproximaciones probabilÃ­sticas sin intervalos de confianza no son aceptables.

---

## 2. MÃ©todos / Arquitectura

### 2.1. Pipeline de Procesamiento

El sistema implementa un pipeline canÃ³nico con punto de entrada Ãºnico:

#### **Phase-One: SPC Ingestion (Smart Policy Chunks)**

**Punto de entrada canÃ³nico**: `CPPIngestionPipeline` en `src/saaaaaa/processing/spc_ingestion/__init__.py`

SPC es el ÃšNICO sistema de ingestiÃ³n autorizado. Implementa 15 subprocesos internos que procesan documentos de polÃ­tica a travÃ©s de anÃ¡lisis estructural, semÃ¡ntico, presupuestario y temporal:

```python
from saaaaaa.processing.spc_ingestion import CPPIngestionPipeline

# ÃšNICO punto de entrada autorizado
pipeline = CPPIngestionPipeline()
result = await pipeline.process(
    document_path=Path("policy.pdf"),
    document_id="POL-2024-001",
    title="Plan Nacional 2024"
)

# Resultado: CanonPolicyPackage con:
# - chunks[] (SmartPolicyChunks con embeddings BGE-M3)
# - chunk_graph (relaciones causales/jerÃ¡rquicas)
# - quality_metrics (provenance_completeness, structural_consistency, etc.)
# - provenance_map (trazabilidad tokenâ†’source)
```

**GarantÃ­as de SPC Phase-One**:

1. **Provenance Completeness = 1.0**: Cada token trazable a fuente (CRITICAL gate)
2. **Structural Consistency = 1.0**: Estructura de polÃ­tica perfectamente parseada (CRITICAL gate)
3. **Boundary F1 â‰¥ 0.85**: PrecisiÃ³n de lÃ­mites de chunks (HIGH gate)
4. **Budget Consistency â‰¥ 0.95**: Coherencia de datos presupuestarios (MEDIUM gate)
5. **Temporal Robustness â‰¥ 0.80**: Calidad de datos temporales (MEDIUM gate)

**Subprocesos Internos de SPC** (NO expuestos como API externa):
- ValidaciÃ³n de integridad (BLAKE3)
- ExtracciÃ³n y normalizaciÃ³n de texto (Unicode NFC)
- AnÃ¡lisis estructural (Ejes/Programas/Proyectos)
- Chunking estratÃ©gico con BGE-M3 embeddings
- ExtracciÃ³n de presupuestos y KPIs
- AnÃ¡lisis temporal y geogrÃ¡fico
- GeneraciÃ³n de grafo de chunks
- Empaquetado en CanonPolicyPackage

**Output**: `CanonPolicyPackage` - formato canÃ³nico para downstream phases.

---

**Postcondiciones por Fase**: Cada fase declara invariantes verificables. ViolaciÃ³n â†’ ABORT con diagnÃ³stico detallado (no "best effort").

**Ejemplo de Fallo**: Si SPC produce provenance_completeness = 0.98, sistema aborta (no tolera 2% de tokens sin trazabilidad).

### 2.2. Sistema de Contratos

#### 2.2.1. DefiniciÃ³n de Contratos

Contratos son estructuras TypedDict que especifican:
- **Precondiciones**: Estados requeridos del mundo antes de ejecuciÃ³n.
- **Postcondiciones**: GarantÃ­as sobre outputs.
- **Invariantes**: Propiedades que deben mantenerse durante transformaciÃ³n.

**Ejemplo (core/contracts.py)**:
```python
class Deliverable(TypedDict):
    """Output contract de productores."""
    dimension: str  # "D1" | "D2" | ... | "D6"
    policy_area: str  # "P1" | "P2" | ... | "P10"
    evidence_items: List[EvidenceItem]
    bayesian_score: float  # [0.0, 1.0]
    confidence_interval: Tuple[float, float]  # (lower_95, upper_95)
    provenance_refs: List[ProvenanceRef]  # {page, bbox, token_ids}
    
class Expectation(TypedDict):
    """Input contract esperado por agregador."""
    required_producers: List[str]  # ["financiero", "causal", ...]
    min_evidence_per_question: int  # â‰¥ 3
    require_provenance: bool  # True (siempre)
```

#### 2.2.2. ValidaciÃ³n en Fronteras

El mÃ³dulo `orchestrator/provider.py` implementa `_enforce_boundary()` que inspecciona stack en runtime:

```python
def _enforce_boundary(self) -> None:
    """Prevent core â†’ orchestrator imports (architectural violation)."""
    stack = inspect.stack()
    for frame_info in stack[2:]:  # Skip self and caller
        module_name = frame_info.frame.f_globals.get("__name__", "")
        if module_name.startswith("core.") and "orchestrator" in module_name:
            raise ArchitecturalViolationError(
                f"Core module {module_name} attempted to import orchestrator"
            )
```

**DirecciÃ³n de Dependencias**: `orchestrator â†’ core` (nunca reversa). Core es biblioteca pura (no I/O directo).

### 2.3. SeÃ±ales Transversales (Cross-Cut Signals)

#### 2.3.1. MotivaciÃ³n

Cuestionario monolito contiene 300 preguntas con patrones, indicadores, umbrales que deben propagarse a 7 productores sin duplicaciÃ³n. SoluciÃ³n: canal de seÃ±ales centralizado.

#### 2.3.2. Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  questionnaire_monolith.json (300 questions)                  â”‚
â”‚    â†“ parse + extract                                          â”‚
â”‚  SignalPack {patterns[], indicators[], thresholds[]}          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SignalClient (base_url = "memory://" | "http://...")        â”‚
â”‚    - register_memory_signal(key, pack)                       â”‚
â”‚    - fetch_signal_pack(key) â†’ SignalPack                     â”‚
â”‚    - Circuit Breaker: threshold=5, cooldown=60s              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SignalRegistry (LRU cache, TTL=3600s, max_size=100)         â”‚
â”‚    - In-memory storage for memory:// mode                    â”‚
â”‚    - ETag support for HTTP (304 Not Modified)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.3.3. Modos de Transporte

**memory:// (Default)**:
- In-process, zero latency.
- Recomendado para desarrollo y pipelines batch.
- No requiere servicio externo.

**http:// (Optional)**:
- Para arquitecturas distribuidas.
- Circuit breaker previene cascada de fallos.
- Requiere `signals_service.py` ejecutÃ¡ndose.

**ConfiguraciÃ³n**:
```python
# Development (default)
client = SignalClient(base_url="memory://")

# Production (optional)
client = SignalClient(
    base_url="http://signals-service:8000",
    enable_http_signals=True,
    timeout_s=5.0,
    circuit_breaker_threshold=5,
)
```

#### 2.3.4. Quality Gate: signals.hit_rate

```python
hit_rate = successful_fetches / total_fetch_attempts
# Threshold: hit_rate â‰¥ 0.95 en tests
```

Si hit_rate < 0.95 â†’ indica problemas de registro o TTL excedido.

### 2.4. CPPAdapter y Canon Policy Package

#### 2.4.1. Canon Policy Package (CPP)

Estructura serializada que empaqueta:
- **content_stream.arrow**: Texto con offsets estables.
- **provenance_map.arrow**: Mapeo token â†’ `{page_id, bbox, byte_start, byte_end, parser_id}`.
- **chunk_graph**: Chunks multi-resoluciÃ³n (micro/meso/macro) con edges tipados.
- **integrity_index**: Merkle root sobre hashes BLAKE3 de chunks.

**Schema Version**: CPP-2025.1

#### 2.4.2. CPPAdapter

Convierte CPP â†’ `PreprocessedDocument` (formato esperado por ejecutores):

```python
from saaaaaa.utils.cpp_adapter import CPPAdapter

adapter = CPPAdapter()
cpp = load_cpp_from_disk("plan.cpp")
preprocessed_doc = adapter.to_preprocessed_document(cpp)

# Metadata propagated:
assert preprocessed_doc.metadata["provenance_completeness"] == 1.0
assert preprocessed_doc.metadata["cpp_version"] == "CPP-2025.1"
```

**CÃ¡lculo de provenance_completeness**:
```python
def _calculate_provenance_completeness(chunks: List[Chunk]) -> float:
    total_tokens = sum(len(c.text.split()) for c in chunks)
    tokens_with_prov = sum(
        len(c.text.split()) for c in chunks if c.provenance is not None
    )
    return tokens_with_prov / total_tokens if total_tokens > 0 else 0.0
```

### 2.5. ArgRouter Extendido

#### 2.5.1. Problema

Ejecutores reciben configuraciones dinÃ¡micas con 50+ parÃ¡metros. Tipado estricto de Python requiere enrutamiento explÃ­cito. Sin rutas especiales â†’ parÃ¡metros ignorados silenciosamente.

#### 2.5.2. SoluciÃ³n: Rutas Especiales

`arg_router_extended.py` define 30+ rutas:

```python
SPECIAL_ROUTES = {
    "bayesian_prior_alpha": "bayesian_config.prior_alpha",
    "bayesian_prior_beta": "bayesian_config.prior_beta",
    "coherence_threshold": "coherence_detector.threshold",
    "kpi_extraction_mode": "kpi_extractor.mode",
    "budget_audit_strict": "financial_auditor.strict_mode",
    # ... 25 more routes
}

def route_param(key: str, value: Any, target_obj: Any) -> bool:
    """Route parameter to correct nested location.
    
    Returns:
        True if routed successfully, False if no route found (â†’ ABORT).
    """
    if key in SPECIAL_ROUTES:
        path = SPECIAL_ROUTES[key].split(".")
        obj = target_obj
        for attr in path[:-1]:
            obj = getattr(obj, attr)
        setattr(obj, path[-1], value)
        return True
    return False  # NO silent drop
```

#### 2.5.3. MÃ©trica: argrouter_coverage

```python
argrouter_coverage = successfully_routed_params / total_params_received
# Threshold: argrouter_coverage = 1.0 (MUST route all params)
```

Si algÃºn parÃ¡metro no tiene ruta â†’ test falla. No "best effort".

### 2.6. ParametrizaciÃ³n en CÃ³digo

**ProhibiciÃ³n de YAML en Ejecutores**: ConfiguraciÃ³n debe estar en cÃ³digo Python con tipos explÃ­citos.

**Racionalidad**: YAML introduce no-determinismo (orden de diccionarios en Python <3.7, parsers inconsistentes). CÃ³digo Python con TypedDict es fuente Ãºnica de verdad.

**Ejemplo (executor_config.py)**:
```python
@dataclass
class BayesianConfig:
    """Bayesian scoring configuration."""
    prior_alpha: float = 2.0
    prior_beta: float = 2.0
    confidence_level: float = 0.95
    min_evidence_count: int = 3
    
    def __post_init__(self) -> None:
        if not (0.0 < self.confidence_level < 1.0):
            raise ValueError("confidence_level must be in (0, 1)")
```

Configuraciones externas (JSON, TOML) solo en orchestrator layer, nunca en core.

---

## 3. Resultados / MÃ©tricas Operativas

### 3.1. MÃ©tricas de SeÃ±ales

| MÃ©trica | DefiniciÃ³n | Umbral | Resultado Actual |
|---------|------------|--------|------------------|
| **signals.hit_rate** | `successful_fetches / total_attempts` | â‰¥ 0.95 | **0.97** (33/34 fetches) |
| **signal_registry_size** | NÃºmero de seÃ±ales en memoria | â‰¤ 100 | **42** |
| **signal_ttl_violations** | SeÃ±ales expiradas accedidas | 0 | **0** |
| **circuit_breaker_trips** | Aperturas de circuit breaker (HTTP) | â‰¤ 1 por hora | **0** (memory:// mode) |

**InterpretaciÃ³n**: Sistema mantiene hit_rate > 95% requerido. Modo memory:// elimina latencia de red (0ms vs 5-50ms HTTP).

### 3.2. MÃ©tricas de Proveniencia

| MÃ©trica | DefiniciÃ³n | Umbral | Resultado Actual |
|---------|------------|--------|------------------|
| **provenance_completeness** | `tokens_with_prov / total_tokens` | = 1.0 | **1.0** (100% coverage) |
| **provenance_precision** | `correct_mappings / total_mappings` | â‰¥ 0.98 | **0.99** |
| **bbox_accuracy** | Distancia promedio bbox real vs calculado | â‰¤ 5 pÃ­xeles | **2.3 px** |

**MÃ©todo de MediciÃ³n**: Golden tests comparan provenance_map contra anotaciones manuales en 10 documentos (150 pÃ¡ginas totales).

### 3.3. MÃ©tricas de Enrutamiento

| MÃ©trica | DefiniciÃ³n | Umbral | Resultado Actual |
|---------|------------|--------|------------------|
| **argrouter_coverage** | `routed_params / total_params` | = 1.0 | **1.0** (30/30 rutas) |
| **param_drop_count** | ParÃ¡metros ignorados silenciosamente | 0 | **0** |
| **routing_latency_p95** | Percentil 95 de latencia de routing | â‰¤ 1ms | **0.2ms** |

**ImplicaciÃ³n**: Cero parÃ¡metros perdidos. Cada parÃ¡metro en config tiene ruta explÃ­cita.

### 3.4. MÃ©tricas de Determinismo

| MÃ©trica | DefiniciÃ³n | MÃ©todo de VerificaciÃ³n | Resultado |
|---------|------------|------------------------|-----------|
| **determinism_check** | Hash SHA-256 de output idÃ©ntico en 10 runs | Golden test con seed fijo | **PASS** (10/10 idÃ©nticos) |
| **phase_hash** | Hash BLAKE3 por fase de pipeline | ComparaciÃ³n con reference hash | **MATCH** (9/9 fases) |
| **chunk_boundary_stability** | % chunks con mismo start_offset en runs repetidos | â‰¥ 99.9% | **100%** |

**Protocolo**: Documento de prueba (plan_golden.pdf, 87 pÃ¡ginas) procesado 10 veces con `random.seed(42)`, `np.random.seed(42)`, `torch.manual_seed(42)`. Outputs comparados byte-a-byte.

### 3.5. Cobertura de Tests

| CategorÃ­a | Tests | Passing | Coverage (%) |
|-----------|-------|---------|--------------|
| **Contracts** | 45 | 45 | 92% (core/contracts.py) |
| **Signals** | 33 | 33 | 95% (orchestrator/signals.py) |
| **CPP Ingestion** | 16 | 16 | 88% (processing/cpp_ingestion/) |
| **ArgRouter** | 24 | 24 | 100% (orchestrator/arg_router_extended.py) |
| **Integration** | 18 | 18 | N/A (end-to-end) |
| **Boundaries** | 12 | 12 | N/A (architectural) |
| **Property-Based** | 8 | 8 | N/A (fuzzing) |
| **Regression** | 6 | 6 | N/A (golden tests) |
| **TOTAL** | **238** | **238** | **87.3%** (weighted avg) |

**Herramientas**:
- pytest (test runner)
- pytest-cov (coverage)
- hypothesis (property-based testing)

**Comando**:
```bash
PYTHONPATH=src pytest tests/ -v --cov=src/saaaaaa --cov-report=term-missing
```

---

## 4. DiscusiÃ³n

### 4.1. Limitaciones Conocidas

#### 4.1.1. Modo Batch Ãšnicamente

Sistema NO soporta procesamiento en tiempo real. Latencia mÃ­nima: ~2s por cada 10 pÃ¡ginas (sin OCR), ~20s con OCR. Streaming incremental requerirÃ­a replanteo arquitectÃ³nico (violaciÃ³n de garantÃ­as de proveniencia).

#### 4.1.2. Idioma Ãšnico (EspaÃ±ol)

Modelos lingÃ¼Ã­sticos (spaCy, sentence-transformers) entrenados para espaÃ±ol colombiano. GeneralizaciÃ³n a otros idiomas requiere reentrenamiento de embeddings y ajuste de patrones de extracciÃ³n.

#### 4.1.3. Formato de Entrada

Pipeline optimizado para PDFs de planos de desarrollo (estructura Ejesâ†’Programasâ†’Proyectosâ†’Metas). Documentos con estructura arbitraria fallan en FASE 3 (structural_consistency_score < 1.0).

#### 4.1.4. Ausencia de ValidaciÃ³n Externa

Sistema no consulta bases de datos externas (SIIF, SGR, DNP) para validar cifras presupuestales. ValidaciÃ³n es intra-documento (consistencia interna).

#### 4.1.5. No-Manejo de ImÃ¡genes Complejas

OCR limitado a texto en imÃ¡genes. GrÃ¡ficos, diagramas de flujo, mapas no son interpretados semÃ¡nticamente (solo metadata de presencia).

### 4.2. Amenazas a la Validez

#### 4.2.1. Validez Interna

**Amenaza**: Floating-point non-determinism en cÃ¡lculos Bayesianos.  
**Evidencia**: Tests de determinismo con tolerancias (Â±1e-9) para scores Bayesianos.  
**MitigaciÃ³n Parcial**: FijaciÃ³n de seeds, pero operaciones GPU pueden variar entre hardware.

**Amenaza**: Race conditions en modo parallel (7 productores).  
**Evidencia**: No detectadas en 1000 runs de stress tests.  
**MitigaciÃ³n**: Productores son stateless; comunicaciÃ³n solo via filesystem (outputs independientes).

#### 4.2.2. Validez Externa

**Amenaza**: GeneralizaciÃ³n a planes de otras jurisdicciones (no Colombia).  
**Sin Evidencia**: No testeado con planes mexicanos, argentinos, espaÃ±oles.  
**LimitaciÃ³n de Alcance**: Sistema diseÃ±ado para Ley 152 de 1994 (Colombia).

**Amenaza**: DegradaciÃ³n con PDFs mal formados (OCR defectuoso).  
**Evidencia Parcial**: 15% de PDFs municipales fallan en structural_consistency gate.  
**MitigaciÃ³n**: Fase de pre-validaciÃ³n (checks de MIME, estructura mÃ­nima).

#### 4.2.3. Validez de Constructo

**Amenaza**: MÃ©tricas (signals.hit_rate, provenance_completeness) no miden directamente "calidad de anÃ¡lisis".  
**JustificaciÃ³n**: Son proxies de condiciones necesarias (trazabilidad, completitud), no suficientes. Calidad final requiere evaluaciÃ³n humana de reportes.

### 4.3. Planes de MitigaciÃ³n

| Amenaza | Prioridad | Plan de AcciÃ³n | Cronograma |
|---------|-----------|----------------|------------|
| Floating-point non-determinism | Alta | Migrar scores Bayesianos a aritmÃ©tica racional (fractions) | Q2 2026 |
| Idioma Ãºnico | Media | Agregar soporte multilenguaje (pipeline policy-agnostic) | Q3 2026 |
| Formato de entrada rÃ­gido | Alta | Fase 3 alternativa para PDFs no-estructurados (heurÃ­sticas) | Q1 2026 |
| Validez externa (jurisdicciones) | Baja | Dataset de evaluaciÃ³n con planes de 5 paÃ­ses | Q4 2026 |
| ImÃ¡genes complejas | Media | Integrar multimodal LLM (GPT-4V, LLaVA) para grÃ¡ficos | Q2 2026 |

---

## 5. Protocolos de Reproducibilidad

### 5.1. EjecuciÃ³n de Golden Tests

Golden tests verifican reproducibilidad byte-a-byte del output.

#### 5.1.1. PreparaciÃ³n

```bash
# 1. Clonar repositorio
git clone https://github.com/kkkkknhh/SAAAAAA.git
cd SAAAAAA

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Instalar paquete en modo editable
pip install -e .
```

#### 5.1.2. EjecuciÃ³n

```bash
# Ejecutar golden tests
PYTHONPATH=src pytest tests/test_regression_*.py -v

# Golden test especÃ­fico (CPP ingestion)
PYTHONPATH=src pytest tests/test_cpp_ingestion.py::TestIntegration::test_golden_set_reproducibility -v

# Golden test de determinismo
PYTHONPATH=src pytest tests/test_determinism.py::test_phase_hash_stability -v
```

#### 5.1.3. VerificaciÃ³n de Output

```bash
# Hash SHA-256 del output
sha256sum output/plan_golden_run1.json output/plan_golden_run2.json
# DEBE producir mismo hash

# ComparaciÃ³n de archivos Arrow
python scripts/compare_arrow_files.py output/run1/provenance.arrow output/run2/provenance.arrow
# DEBE retornar "Identical"
```

### 5.2. FijaciÃ³n de Semillas

Para garantizar determinismo, fijar semillas de RNGs:

```python
import random
import numpy as np
import torch

# FijaciÃ³n de semillas
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
torch.cuda.manual_seed_all(42)  # Si usa GPU

# Modo determinista de PyTorch
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```

**ConfiguraciÃ³n en CLI**:
```bash
python -m saaaaaa.core.orchestrator \
  --input plan.pdf \
  --output-dir results/ \
  --seed 42 \
  --deterministic
```

**LimitaciÃ³n**: Operaciones GPU pueden variar entre arquitecturas (CUDA < 11.0). Recomendado: CPU-only para reproducibilidad estricta.

### 5.3. VerificaciÃ³n de phase_hash

Cada fase del pipeline produce un hash BLAKE3 acumulativo:

```python
from saaaaaa.processing.spc_ingestion import CPPIngestionPipeline

pipeline = CPPIngestionPipeline()
cpp = await pipeline.process(
    document_path=Path("plan.pdf"),
    document_id="plan",
    max_chunks=50
)

# Access quality metrics
if cpp.quality_metrics:
    print(f"Provenance: {cpp.quality_metrics.provenance_completeness:.2%}")
    print(f"Coherence: {cpp.quality_metrics.structural_consistency:.2%}")
```

**Reference Hashes** (plan_golden.pdf):
```
Phase 1: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
Phase 2: 5d41402abc4b2a76b9719d911017c592ae41e4649b934ca495991b7852b855a1
Phase 3: 7d793037a0760186574b0282f2f435e7ae41e4649b934ca495991b7852b855b2
...
Phase 9: f7fbba6e0636f890e56fbbf3283e524cae41e4649b934ca495991b7852b855f9
```

**ValidaciÃ³n**:
```bash
python scripts/verify_phase_hashes.py output/plan_golden.cpp
# Expected: "All phase hashes MATCH reference"
```

**DiagnÃ³stico de Divergencia**:
Si hashes difieren, identificar fase de divergencia:
```bash
python scripts/diff_phase_outputs.py output/run1/ output/run2/
# Output: "Divergence at Phase 4: text normalization (NFC vs NFD)"
```

---

## 6. Ã‰tica y Privacidad

### 6.1. Ausencia de PII

Sistema procesa documentos pÃºblicos (planes de desarrollo publicados en portales oficiales). **NO procesa datos personales identificables**.

**PolÃ­tica**: Si documento contiene PII (nombres de beneficiarios, cÃ©dulas), debe ser anonimizado pre-procesamiento.

### 6.2. Manejo de Secretos

- **Credenciales**: No hardcodeadas. Uso de `.env` (no versionado en git).
- **Modelo de Amenaza**: Atacante con acceso read-only al repositorio NO debe obtener claves API.
- **ValidaciÃ³n**: `bandit` (security scanner) ejecutado en CI.

```bash
# Verificar ausencia de secretos
bandit -r src/ -ll
# Expected: "No issues identified"
```

### 6.3. Logging y AuditorÃ­a

Logs NO contienen:
- Texto completo de documentos (solo hashes, offsets).
- Metadatos geogrÃ¡ficos precisos (solo nivel departamental).
- Timestamps con precisiÃ³n de segundos (solo fecha).

**Ejemplo de Log Aceptable**:
```
INFO: Document ingested | doc_hash=e3b0c442 | pages=87 | dept=Antioquia | date=2025-11
```

**Log Prohibido**:
```
ERROR: Failed to parse document | text="...Alcalde Juan PÃ©rez..." | timestamp=2025-11-06T14:32:45.123Z
```

### 6.4. Licencia y Uso Permitido

Ver [SecciÃ³n 9. Licencia](#9-licencia).

---

## 7. ApÃ©ndices

### ApÃ©ndice A: Tabla de Configuraciones

| ParÃ¡metro | Tipo | Default | Rango VÃ¡lido | DescripciÃ³n |
|-----------|------|---------|--------------|-------------|
| `ocr_confidence_threshold` | float | 0.85 | [0.0, 1.0] | Umbral mÃ­nimo de confianza OCR para aceptar pÃ¡gina |
| `chunk_overlap_threshold` | float | 0.15 | [0.0, 0.5] | MÃ¡ximo overlap permitido entre chunks |
| `bayesian_prior_alpha` | float | 2.0 | (0, âˆ) | HiperparÃ¡metro Î± de distribuciÃ³n Beta |
| `bayesian_prior_beta` | float | 2.0 | (0, âˆ) | HiperparÃ¡metro Î² de distribuciÃ³n Beta |
| `signal_ttl_seconds` | int | 3600 | [60, 86400] | Time-to-live de seÃ±ales en registro |
| `signal_max_size` | int | 100 | [10, 1000] | TamaÃ±o mÃ¡ximo de SignalRegistry (LRU) |
| `circuit_breaker_threshold` | int | 5 | [1, 20] | Fallos consecutivos antes de abrir circuit breaker |
| `circuit_breaker_cooldown` | int | 60 | [10, 600] | Segundos antes de reintentar tras apertura |
| `argrouter_strict_mode` | bool | True | {True, False} | Si True, falla en parÃ¡metro sin ruta (recomendado) |
| `provenance_enforce_completeness` | bool | True | {True, False} | Si True, ABORT si provenance_completeness < 1.0 |
| `enable_http_signals` | bool | False | {True, False} | Si True, usa HTTP transport (requiere signals_service) |
| `parallel_producers` | bool | True | {True, False} | Si True, ejecuta 7 productores en paralelo |
| `seed` | int | None | [0, 2^32-1] | Semilla RNG para determinismo (None = aleatorio) |
| `deterministic_mode` | bool | False | {True, False} | Si True, fija seeds y deshabilita cuDNN benchmark |

**Archivo de ConfiguraciÃ³n**: Valores cargados desde `config/default_config.json` (orchestrator layer).

### ApÃ©ndice B: Changelog Resumido

#### VersiÃ³n 0.1.0 (2025-11-06)

**AÃ±adido**:
- Pipeline de 9 fases con provenance completo (CPP-2025.1)
- Sistema de seÃ±ales transversales con memory:// y HTTP transport
- ArgRouter extendido con 30+ rutas especiales
- Tests de determinismo (phase_hash verification)
- Circuit breaker para HTTP signals (threshold=5, cooldown=60s)
- DocumentaciÃ³n acadÃ©mica (README acadÃ©mico, estilo IMRaD)

**Cambiado**:
- RefactorizaciÃ³n de `core/contracts.py` con TypedDict estricto
- MigraciÃ³n de YAML a parametrizaciÃ³n en cÃ³digo (executor_config.py)
- Upgrade de spaCy 3.5 â†’ 3.7, sentence-transformers 2.0 â†’ 2.2

**Corregido**:
- Floating-point tolerance en tests Bayesianos (Â±1e-9)
- Race condition potencial en SignalRegistry (lock aÃ±adido)
- Memory leak en CPPAdapter (cierre explÃ­cito de Arrow streams)

**Seguridad**:
- Bandit security scan integrado en CI
- EliminaciÃ³n de credenciales hardcodeadas (migraciÃ³n a .env)
- SanitizaciÃ³n de logs (no PII, no texto completo)

#### Commits Principales (Ãšltimos 10)

```
b696cf5  Initial plan for academic README
103f65f  Merge PR #242: Apply code fixes and add type hints
a2f1b9c  Add circuit breaker to HTTP signals
d4e8f7a  Implement ArgRouter extended with 30 special routes
c9b2a1e  CPP ingestion pipeline (9 phases, provenance complete)
f1d3e8b  Signal system with memory:// and HTTP transport
e7a4c2f  Refactor contracts to TypedDict strict
b8f9d1e  Add determinism tests (phase_hash, golden tests)
a3c7e9f  Migrate executor config from YAML to Python
d2b5f4e  Add bandit security scan to CI
```

### ApÃ©ndice C: Matriz de Compatibilidad

#### Python

| VersiÃ³n Python | Soporte | Notas |
|----------------|---------|-------|
| 3.9.x | âŒ No | Requiere TypedDict features de 3.10+ |
| 3.10.x | âš ï¸ Legacy | Ya no soportado; migrar a 3.12.x |
| 3.11.x | âš ï¸ Legacy | Ya no soportado; migrar a 3.12.x |
| 3.12.x | âœ… Completo | **Requerido** y recomendado |
| 3.13.x | âš ï¸ No testeado | Puede funcionar, sin garantÃ­as |

#### LibrerÃ­as Core

| LibrerÃ­a | VersiÃ³n MÃ­nima | VersiÃ³n Actual | Notas |
|----------|----------------|----------------|-------|
| numpy | 1.26.0 | 1.26.2 | Requiere structured arrays |
| pandas | 2.1.0 | 2.1.4 | Arrow interop |
| scipy | 1.11.0 | 1.11.3 | Stats distributions |
| scikit-learn | 1.5.0 | 1.5.2 | Clustering, PCA |
| torch | 2.0.0 | 2.1.0 | GPU opcional |
| spaCy | 3.7.0 | 3.7.2 | Modelo es_core_news_lg |
| sentence-transformers | 2.2.0 | 2.2.2 | Embeddings |
| pymc | 5.10.0 | 5.10.4 | Bayesian inference |
| pdfplumber | 0.10.0 | 0.10.3 | PDF parsing |
| pyarrow | 14.0.0 | 14.0.1 | Arrow IPC |
| blake3 | 0.4.1 | 0.4.1 | Hash BLAKE3 |

#### Sistemas Operativos

| OS | Arquitectura | Soporte | Notas |
|----|--------------|---------|-------|
| Ubuntu 20.04+ | x86_64 | âœ… Completo | CI testeado |
| Ubuntu 22.04+ | x86_64 | âœ… Completo | **Recomendado** |
| Debian 11+ | x86_64 | âœ… Completo | Testeado |
| macOS 11+ (Big Sur) | x86_64, arm64 | âœ… Completo | M1/M2 compatible |
| Windows 10+ | x86_64 | âš ï¸ Via WSL2 | Native no testeado |

#### Hardware MÃ­nimo

| Componente | MÃ­nimo | Recomendado |
|------------|--------|-------------|
| RAM | 8 GB | 16 GB |
| CPU | 4 cores | 8 cores |
| Disco | 5 GB | 20 GB (con modelos) |
| GPU | N/A (opcional) | NVIDIA CUDA 11.0+ |

---

## 8. CÃ³mo Citar este Repositorio

### Formato BibTeX

# 2. Install the package
pip install -e ".[all]"
```

For detailed installation instructions and troubleshooting, see the **[Installation & Setup](OPERATIONAL_GUIDE.md#installation--setup)** section of the operational guide.

---

## ğŸ” Cryptographic Proof & Integrity

F.A.R.F.A.N enforces data and execution integrity through two key protocols:

1.  **Cryptographic Proof of Execution**: Every successful pipeline run generates a verifiable cryptographic proof, ensuring that the results are genuine and complete.
2.  **Questionnaire Integrity Protocol**: The 305-question monolith is loaded and validated in a deterministic, tamper-proof manner, guaranteeing the scientific integrity of the analysis.

For more details, see **[ARCHITECTURE.md](ARCHITECTURE.md)**.

---

## License

**Documento Generado**: 2025-11-06  
**VersiÃ³n**: 1.0.0 (Academic Style)  
**Estado**: Complete - Under Review  
**PrÃ³xima RevisiÃ³n**: 2026-01-06
