# F.A.R.F.A.N: Framework for Advanced Retrieval of Administrative Narratives

**Un Pipeline Mecan√≠stico de Pol√≠ticas para el An√°lisis de Planes de Desarrollo Colombianos**

[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Licencia](https://img.shields.io/badge/licencia-MIT-green.svg)](LICENSE)
[![Estado](https://img.shields.io/badge/estado-producci√≥n-brightgreen.svg)]()

---

## üéØ Resumen Ejecutivo

F.A.R.F.A.N es un marco sofisticado de an√°lisis basado en evidencia para planes de desarrollo municipales y departamentales colombianos. Integra **584 m√©todos anal√≠ticos** distribuidos en **7 productores especializados** y **1 agregador**, entregando an√°lisis de pol√≠ticas riguroso y reproducible a trav√©s de un pipeline determinista de 9 fases con trazabilidad completa (`provenance_completeness = 1.0`).

**Innovaci√≥n Clave**: An√°lisis mecan√≠stico de pol√≠ticas combinando (1) pipeline de ingesta determinista de 9 fases, (2) sistema de se√±ales transversales con transporte memory:// y HTTP, (3) enrutamiento extendido de argumentos (30+ rutas especiales), y (4) contratos expl√≠citos de entrada/salida con validaci√≥n en fronteras.

**Alcance del An√°lisis**: 300 preguntas de evaluaci√≥n organizadas en 6 dimensiones (D1-D6: Insumos, Actividades, Productos, Resultados, Impactos, Causalidad) sobre 10 √°reas de pol√≠tica (PA01-PA10), generando reportes en tres niveles de agregaci√≥n: MICRO (respuestas at√≥micas por pregunta, 150-300 palabras), MESO (an√°lisis de clusters por dimensi√≥n-√°rea), y MACRO (clasificaci√≥n y recomendaciones).

---

## üìö Tabla de Contenidos

1. [Inicio R√°pido](#-inicio-r√°pido)
2. [¬øQu√© es F.A.R.F.A.N?](#-qu√©-es-farfan)
3. [Caracter√≠sticas Clave](#-caracter√≠sticas-clave)
4. [Requisitos del Sistema](#-requisitos-del-sistema)
5. [Instalaci√≥n](#-instalaci√≥n)
6. [Uso](#-uso)
7. [Arquitectura](#-arquitectura)
8. [Pruebas](#-pruebas)
9. [Temas Avanzados](#-temas-avanzados)
10. [Desarrollo](#-desarrollo)
11. [Soluci√≥n de Problemas](#-soluci√≥n-de-problemas)
12. [Contribuir](#-contribuir)
13. [Licencia y Citaci√≥n](#-licencia-y-citaci√≥n)

---

## üöÄ Inicio R√°pido

### Configuraci√≥n en 5 Minutos

```bash
# 1. Clonar repositorio
git clone https://github.com/PEROPOROBTANTE/F.A.R.F.A.N-MECHANISTIC_POLICY_PIPELINE_FINAL.git
cd F.A.R.F.A.N-MECHANISTIC_POLICY_PIPELINE_FINAL

# 2. Instalar (automatizado - instala todas las dependencias)
bash install.sh

# 3. Activar entorno
source farfan-env/bin/activate

# 4. Verificar instalaci√≥n
python verify_dependencies.py

# 5. Ejecutar primer an√°lisis
python scripts/run_policy_pipeline_verified.py \
    --plan data/plans/Plan_1.pdf \
    --artifacts-dir artifacts/plan1
```

**Tiempo Esperado**: 2-3 minutos para an√°lisis completo

**Salida Esperada**:
```
PIPELINE_VERIFIED=1
Fases: 11 completadas, 0 fallidas
Artefactos: artifacts/plan1/verification_manifest.json
```

---

## üõ°Ô∏è Fase 0: Puerta de Validaci√≥n Estricta

### El Contrato Pre-Ejecuci√≥n

**La Fase 0 es el marco de bootstrap determin√≠stico de F.A.R.F.A.N**‚Äîuna puerta de validaci√≥n de cero tolerancia que establece condiciones de ejecuci√≥n inmutables antes de que cualquier an√°lisis de pol√≠ticas comience.

#### üìä Dashboard de Aplicaci√≥n

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  FASE 0: ESTADO DE VALIDACI√ìN PRE-EJECUCI√ìN                   ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                                ‚ïë
‚ïë  P0.0 ‚îÇ BOOTSTRAP           ‚îÇ ‚úÖ RuntimeConfig      ‚îÇ ESTRICTO‚ïë
‚ïë       ‚îÇ                     ‚îÇ ‚úÖ Seed Registry      ‚îÇ         ‚ïë
‚ïë       ‚îÇ                     ‚îÇ ‚úÖ Manifest Builder   ‚îÇ         ‚ïë
‚ïë                                                                ‚ïë
‚ïë  P0.1 ‚îÇ VERIFICACI√ìN ENTRADA ‚îÇ ‚úÖ Hash PDF Plan      ‚îÇ CRYPTO  ‚ïë
‚ïë       ‚îÇ                     ‚îÇ ‚úÖ Hash Cuestion.     ‚îÇ SHA-256 ‚ïë
‚ïë                                                                ‚ïë
‚ïë  P0.2 ‚îÇ CONTROLES ARRANQUE  ‚îÇ ‚úÖ PROD: Fatal        ‚îÇ CUSTODIA‚ïë
‚ïë       ‚îÇ                     ‚îÇ ‚ö†Ô∏è  DEV:  Advertir    ‚îÇ         ‚ïë
‚ïë                                                                ‚ïë
‚ïë  P0.3 ‚îÇ DETERMINISMO        ‚îÇ ‚úÖ Semilla Python RNG ‚îÇ OBLIG.  ‚ïë
‚ïë       ‚îÇ                     ‚îÇ ‚úÖ Semilla NumPy      ‚îÇ         ‚ïë
‚ïë                                                                ‚ïë
‚ïë  SALIDA ‚îÇ CONDICI√ìN PUERTA    ‚îÇ self.errors == []   ‚îÇ AT√ìMICO ‚ïë
‚ïë       ‚îÇ                     ‚îÇ _bootstrap_failed=F ‚îÇ         ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

#### üö® Pol√≠tica de Fallos: Fallar R√°pido, Fallar Limpio, Fallar Determin√≠sticamente

**Cuando la Fase 0 falla**:
1. ‚ùå **Aborto Inmediato**: Sin ejecuci√≥n de Fase 1
2. üìã **Generaci√≥n de Manifiesto**: `success: false` con razones espec√≠ficas de error
3. üî¥ **C√≥digo de Salida 1**: `PIPELINE_VERIFIED=0` impreso a stdout
4. üîç **Rastro de Auditor√≠a**: Log completo de claims en `execution_claims.json`

**Racionalidad del Dise√±o**: En contextos de auditor√≠a p√∫blica, **la reproducibilidad byte-a-byte es un requisito legal**. La Fase 0 asegura que cada ejecuci√≥n:
- ‚úÖ Procede con **condiciones verificadas y determin√≠sticas**, O
- ‚ùå Falla con **mensajes de error claros y accionables**

**Sin Estados "Tal Vez Funcio√≥"**. Sin degradaci√≥n silenciosa. Sin deriva de configuraci√≥n ambigua.

#### üìö Documentaci√≥n

- **Especificaci√≥n Detallada**: [docs/phases/phase_0/P00-ES_v1.0.md](docs/phases/phase_0/P00-ES_v1.0.md)
- **Versi√≥n en Ingl√©s**: [docs/phases/phase_0/P00-EN_v1.0.md](docs/phases/phase_0/P00-EN_v1.0.md)

---

## üí° ¬øQu√© es F.A.R.F.A.N?

F.A.R.F.A.N (Framework for Advanced Retrieval of Administrative Narratives) es un pipeline mecan√≠stico de pol√≠ticas dise√±ado para el an√°lisis riguroso y basado en evidencia de planes de desarrollo municipales colombianos.

### Planteamiento del Problema

La evaluaci√≥n ex-ante de planes de desarrollo requiere procesamiento anal√≠tico de documentos semi-estructurados (100-300 p√°ginas) bajo m√∫ltiples dimensiones: viabilidad financiera, coherencia l√≥gica, causalidad expl√≠cita, trazabilidad presupuestal, alineaci√≥n normativa y evidencia emp√≠rica. Los enfoques tradicionales presentan tres deficiencias:

1. **P√©rdida de Trazabilidad**: Extracci√≥n de texto sin mapeo p√°gina-token impide auditor√≠a de inferencias
2. **Procesamiento No-Determinista**: Variaciones en chunking sem√°ntico y resoluci√≥n de dependencias producen outputs no reproducibles
3. **Triangulaci√≥n Manual**: S√≠ntesis multi-m√©todo requiere integraci√≥n manual, introduciendo sesgos de confirmaci√≥n

### Enfoque de Soluci√≥n

F.A.R.F.A.N integra:

1. **Determinismo de Pipeline**: Pipeline can√≥nico de 9 fases con postcondiciones verificables; fallo en cualquier fase ‚Üí ABORT (no degradaci√≥n gradual)
2. **Se√±ales Transversales**: Registro centralizado de patrones, indicadores, umbrales desde cuestionario monolito hacia todos los ejecutores, con transporte memory:// (in-process) o HTTP (con circuit breaker)
3. **Proveniencia Completa**: Cada token ‚Üí `{page_id, bbox, byte_range, parser_id}` mediante Arrow IPC, permitiendo auditor√≠a forense
4. **ArgRouter Extendido**: 30+ rutas especiales eliminan ca√≠das silenciosas de par√°metros (`argrouter_coverage = 1.0`)
5. **Contratos Expl√≠citos**: TypedDict con validaci√≥n en fronteras (orchestrator ‚Üî core), detectando violaciones arquitect√≥nicas en runtime

**Racionalidad del Determinismo**: En auditor√≠a p√∫blica, reproducibilidad byte-a-byte es requisito legal. Aproximaciones probabil√≠sticas sin intervalos de confianza no son aceptables.

---

## ‚ú® Caracter√≠sticas Clave

### Capacidades Principales

- **üîí Pipeline Determinista**: Procesamiento de 9 fases con prueba criptogr√°fica de ejecuci√≥n
- **üìä An√°lisis Integral**: 300 preguntas en 6 dimensiones y 10 √°reas de pol√≠tica
- **üîç Proveniencia Completa**: 100% trazabilidad token-a-fuente (`provenance_completeness = 1.0`)
- **üéØ Sistema de Se√±ales**: Registro centralizado de patrones con transporte memory:// y HTTP
- **‚ö° Enrutamiento Extendido**: 30+ rutas de argumentos sin ca√≠das silenciosas
- **üõ°Ô∏è Aplicaci√≥n de Contratos**: Contratos TypedDict con validaci√≥n en fronteras en runtime
- **üìà Puertas de Calidad**: M√©tricas de consistencia estructural, precisi√≥n de proveniencia, boundary F1
- **üîê Integridad Criptogr√°fica**: Manifiesto de verificaci√≥n basado en HMAC para todos los artefactos

### Aspectos T√©cnicos Destacados

| Caracter√≠stica | Especificaci√≥n | Verificaci√≥n |
|----------------|----------------|--------------|
| **Completitud de Proveniencia** | 100% | Golden tests en 150 p√°ginas |
| **Cobertura ArgRouter** | 100% (30/30 rutas) | Unit tests |
| **Tasa de Acierto de Se√±ales** | ‚â• 95% | Integration tests |
| **Determinismo** | Id√©ntico byte-a-byte | 10 ejecuciones con seed fijo |
| **Estabilidad de Hash de Fase** | 9/9 fases coinciden | Verificaci√≥n BLAKE3 |
| **Cobertura de Tests** | 87.3% promedio ponderado | 238 tests pasando |

---

## üñ•Ô∏è Requisitos del Sistema

### Requisitos M√≠nimos

| Componente | M√≠nimo | Recomendado |
|------------|--------|-------------|
| **SO** | Ubuntu 20.04+ / Debian 11+ | Ubuntu 22.04+ |
| **Python** | 3.12.x | 3.12.3+ |
| **RAM** | 8 GB | 16 GB |
| **CPU** | 4 n√∫cleos | 8 n√∫cleos |
| **Disco** | 5 GB libres | 20 GB (con modelos) |
| **GPU** | Opcional | NVIDIA CUDA 11.0+ |

### Plataformas Soportadas

| Plataforma | Arquitectura | Nivel de Soporte | Notas |
|------------|--------------|------------------|-------|
| Ubuntu 20.04+ | x86_64 | ‚úÖ Completo | Testeado en CI |
| Ubuntu 22.04+ | x86_64 | ‚úÖ Completo | **Recomendado** |
| Debian 11+ | x86_64 | ‚úÖ Completo | Testeado |
| macOS 11+ | x86_64, arm64 | ‚úÖ Completo | Compatible M1/M2 |
| Windows 10+ | x86_64 | ‚ö†Ô∏è V√≠a WSL2 | Nativo no testeado |

---

## üì¶ Instalaci√≥n

### Instalaci√≥n Automatizada (Recomendada)

```bash
# Un solo comando instala todo
bash install.sh
```

**Qu√© instala**:
- ‚úÖ Dependencias del sistema (build-essential, gfortran, ghostscript, graphviz, JRE)
- ‚úÖ Entorno virtual Python 3.12 (`farfan-env/`)
- ‚úÖ Todos los paquetes Python con versiones exactas compatibles
- ‚úÖ Diagn√≥sticos de verificaci√≥n

**Tiempo de instalaci√≥n**: 10-15 minutos (dependiente de red)

### Instalaci√≥n Manual

#### Linux (Ubuntu/Debian)

```bash
# 1. Instalar dependencias del sistema
sudo apt-get update && sudo apt-get install -y \
  build-essential python3.12-dev gfortran libopenblas-dev libhdf5-dev \
  ghostscript python3-tk libgraphviz-dev graphviz default-jre

# 2. Crear entorno virtual
python3.12 -m venv farfan-env
source farfan-env/bin/activate

# 3. Actualizar herramientas
pip install --upgrade pip setuptools wheel

# 4. Instalar dependencias
pip install --no-cache-dir -r requirements.txt

# 5. Forzar versiones compatibles
pip install --force-reinstall --no-deps numpy==1.26.4 opencv-python-headless==4.10.0.84

# 6. Instalar paquete
pip install --no-cache-dir -e .
```

#### macOS (Homebrew)

```bash
# 1. Instalar dependencias del sistema
brew install python@3.12 icu4c pkg-config ghostscript graphviz openjdk

# 2. Crear entorno virtual
python3.12 -m venv farfan-env
source farfan-env/bin/activate

# 3. Instalar dependencias (igual que Linux pasos 3-6)
pip install --upgrade pip setuptools wheel
pip install --no-cache-dir -r requirements.txt
pip install --force-reinstall --no-deps numpy==1.26.4 opencv-python-headless==4.10.0.84
pip install --no-cache-dir -e .
```

### Verificaci√≥n

```bash
# Activar entorno
source farfan-env/bin/activate

# Diagn√≥stico r√°pido
python diagnose_import_error.py

# Verificaci√≥n completa de dependencias
python scripts/verify_dependencies.py

# Verificaci√≥n integral de salud
bash comprehensive_health_check.sh
```

**Salida esperada**:
```
‚úì transformers: 4.41.2
‚úì sentence-transformers: 3.1.0
‚úì accelerate: 1.2.1
‚úì Cargadas exitosamente 22 clases
Aprobado: 5/6 verificaciones
```

### Dependencias Cr√≠ticas

| Paquete | Versi√≥n | Prop√≥sito | Restricci√≥n |
|---------|---------|-----------|-------------|
| `transformers` | 4.41.2 | Transformers NLP | `>=4.41.0,<4.42.0` (evitar bug TorchTensorParallelPlugin) |
| `sentence-transformers` | 3.1.0 | Embeddings sem√°nticos | `>=3.1.0,<3.2.0` |
| `accelerate` | 1.2.1 | Aceleraci√≥n de modelos | Versi√≥n estable |
| `pymc` | 5.16.2 | Inferencia Bayesiana | Versi√≥n exacta |
| `pytensor` | 2.25.5 | Operaciones tensoriales | `>=2.25.1,<2.26` |
| `scikit-learn` | 1.6.1 | Algoritmos ML | `>=1.6.0` |
| `numpy` | 1.26.4 | Computaci√≥n num√©rica | Versi√≥n exacta (compatibilidad ABI) |

---

## üéÆ Uso

### Ejecuci√≥n B√°sica

#### Modo 1: Pipeline Verificado (Producci√≥n)

```bash
python scripts/run_policy_pipeline_verified.py \
    --plan data/plans/Plan_1.pdf \
    --artifacts-dir artifacts/plan1
```

**Salidas**:
- `verification_manifest.json` - Manifiesto criptogr√°fico con HMAC
- `execution_claims.json` - Log de ejecuci√≥n estructurado
- `cpp_metadata.json` - Metadatos de ingesta SPC
- `preprocessed_doc_metadata.json` - Metadatos de procesamiento de documento
- `results_summary.json` - Resumen de resultados de an√°lisis

**Verificaci√≥n**:
```bash
# Verificar √©xito
grep "PIPELINE_VERIFIED=1" artifacts/plan1/verification_manifest.json

# Verificar integridad HMAC
python3 -c "
import json
from saaaaaa.core.orchestrator.verification_manifest import verify_manifest_integrity

with open('artifacts/plan1/verification_manifest.json') as f:
    manifest = json.load(f)

is_valid, message = verify_manifest_integrity(manifest, 'default-dev-key-change-in-production')
print(f'Verificaci√≥n HMAC: {message}')
"
```

#### Modo 2: An√°lisis Simple (Desarrollo)

```bash
python scripts/run_complete_analysis_plan1.py
```

**Caso de uso**: Pruebas r√°pidas y desarrollo

#### Modo 3: Pipeline Personalizado (Avanzado)

```python
import asyncio
from pathlib import Path
from saaaaaa.processing.spc_ingestion import CPPIngestionPipeline
from saaaaaa.utils.spc_adapter import SPCAdapter
from saaaaaa.core.orchestrator import Orchestrator
from saaaaaa.core.orchestrator.factory import build_processor

async def pipeline_personalizado():
    # Paso 1: Ingesta SPC
    input_path = Path('data/plans/Plan_1.pdf')
    cpp_pipeline = CPPIngestionPipeline(questionnaire_path=None)
    cpp = await cpp_pipeline.process(
        document_path=input_path,
        document_id='Plan_Personalizado',
        title='An√°lisis Personalizado',
        max_chunks=100
    )

    # Paso 2: Adaptaci√≥n
    adapter = SPCAdapter()
    preprocessed = adapter.to_preprocessed_document(cpp, document_id='Plan_Personalizado')

    # Paso 3: Orquestaci√≥n
    processor = build_processor()
    orchestrator = Orchestrator(
        monolith=processor.questionnaire,
        catalog=processor.factory.catalog
    )

    results = await orchestrator.process_development_plan_async(
        pdf_path=str(input_path),
        preprocessed_document=preprocessed
    )

    return results

asyncio.run(pipeline_personalizado())
```

### Procesamiento por Lotes

```bash
#!/bin/bash
# Procesar m√∫ltiples planes

PLANES=(
    "data/plans/Plan_1.pdf"
    "data/plans/Plan_2.pdf"
    "data/plans/Plan_3.pdf"
)

for i in "${!PLANES[@]}"; do
    plan="${PLANES[$i]}"
    plan_num=$((i + 1))

    python scripts/run_policy_pipeline_verified.py \
        --plan "$plan" \
        --artifacts-dir "artifacts/lote_plan${plan_num}"

    if [ $? -eq 0 ]; then
        echo "‚úì Plan $plan_num completado"
    else
        echo "‚úó Plan $plan_num fall√≥"
        exit 1
    fi
done
```

---

## üèóÔ∏è Arquitectura

### Visi√≥n General del Sistema

F.A.R.F.A.N sigue un **pipeline determin√≠stico de Fase 0 + 9 fases** con puertas de calidad estrictas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 0: Validaci√≥n Pre-Ejecuci√≥n                                  ‚îÇ
‚îÇ   Entrada:  ENV vars, ruta plan, ruta cuestionario                ‚îÇ
‚îÇ   Salida:   RuntimeConfig validado, hashes verificados, semillas  ‚îÇ
‚îÇ   Puerta:   self.errors == [] AND _bootstrap_failed = False       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 1: Adquisici√≥n e Integridad                                   ‚îÇ
‚îÇ   Entrada:  file_path (Path)                                    ‚îÇ
‚îÇ   Salida:   manifest.initial {blake3_hash, mime_type, byte_size}‚îÇ
‚îÇ   Puerta:   blake3_hash debe ser 64 caracteres hex              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 2: Descomposici√≥n de Formato                               ‚îÇ
‚îÇ   Entrada:  manifest.initial                                    ‚îÇ
‚îÇ   Salida:   raw_object_tree {pages[], fonts[], images[]}        ‚îÇ
‚îÇ   Puerta:   len(pages) > 0                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 3: Normalizaci√≥n Estructural (Consciente de Pol√≠ticas)     ‚îÇ
‚îÇ   Entrada:  raw_object_tree                                     ‚îÇ
‚îÇ   Salida:   policy_graph.prelim {Ejes, Programas, Proyectos}    ‚îÇ
‚îÇ   Puerta:   structural_consistency_score ‚â• 1.0                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
                    [... contin√∫a hasta Fase 9]
```

### Componentes Principales

#### 1. Pipeline de Ingesta SPC

**Punto de Entrada**: `CPPIngestionPipeline` en `src/saaaaaa/processing/spc_ingestion/__init__.py`

**Garant√≠as**:
- Completitud de Proveniencia = 1.0 (puerta CR√çTICA)
- Consistencia Estructural = 1.0 (puerta CR√çTICA)
- Boundary F1 ‚â• 0.85 (puerta ALTA)
- Consistencia Presupuestal ‚â• 0.95 (puerta MEDIA)

**Salida**: `CanonPolicyPackage` - formato can√≥nico para fases posteriores

#### 2. Sistema de Contratos

Los contratos son estructuras TypedDict que especifican:
- **Precondiciones**: Estados del mundo requeridos antes de la ejecuci√≥n
- **Postcondiciones**: Garant√≠as sobre las salidas
- **Invariantes**: Propiedades mantenidas durante la transformaci√≥n

```python
class Deliverable(TypedDict):
    """Contrato de salida de productores."""
    dimension: str  # "D1" | "D2" | ... | "D6"
    policy_area: str  # "P1" | "P2" | ... | "P10"
    evidence_items: List[EvidenceItem]
    bayesian_score: float  # [0.0, 1.0]
    confidence_interval: Tuple[float, float]
    provenance_refs: List[ProvenanceRef]
```

#### 3. Sistema de Se√±ales

**Arquitectura**:
```
questionnaire_monolith.json (300 preguntas)
    ‚Üì parse + extract
SignalPack {patterns[], indicators[], thresholds[]}
    ‚Üì
SignalClient (base_url = "memory://" | "http://...")
    ‚Üì
SignalRegistry (cach√© LRU, TTL=3600s, max_size=100)
```

**Modos de Transporte**:
- **memory://** (Por defecto): In-process, latencia cero
- **http://** (Opcional): Arquitecturas distribuidas con circuit breaker

#### 4. ArgRouter Extendido

**Problema**: Los ejecutores reciben 50+ par√°metros din√°micos. El tipado estricto de Python requiere enrutamiento expl√≠cito.

**Soluci√≥n**: 30+ rutas especiales eliminan ca√≠das silenciosas de par√°metros

```python
SPECIAL_ROUTES = {
    "bayesian_prior_alpha": "bayesian_config.prior_alpha",
    "coherence_threshold": "coherence_detector.threshold",
    "kpi_extraction_mode": "kpi_extractor.mode",
    # ... 27 rutas m√°s
}
```

**M√©trica**: `argrouter_coverage = 1.0` (DEBE enrutar todos los par√°metros)

### Flujo de Datos

```
Documento de Pol√≠tica (PDF)
    ‚Üì
Ingesta SPC (9 fases)
    ‚Üì
CanonPolicyPackage {content, provenance, chunk_graph, integrity_index}
    ‚Üì
SPCAdapter ‚Üí PreprocessedDocument
    ‚Üì
Orchestrator (300 preguntas)
    ‚Üì
7 Productores (ejecuci√≥n paralela)
    ‚Üì
Ensamblaje de Evidencia
    ‚Üì
Validaci√≥n y Puntuaci√≥n
    ‚Üì
Reporte Final (MICRO/MESO/MACRO)
```

### M√©tricas de Calidad

| M√©trica | Definici√≥n | Umbral | Actual |
|---------|------------|--------|--------|
| **provenance_completeness** | `tokens_con_prov / total_tokens` | = 1.0 | **1.0** |
| **signals.hit_rate** | `fetches_exitosos / intentos_totales` | ‚â• 0.95 | **0.97** |
| **argrouter_coverage** | `params_enrutados / params_totales` | = 1.0 | **1.0** |
| **determinism_check** | SHA-256 id√©ntico en 10 ejecuciones | PASS | **PASS** |

---

## üß™ Pruebas

### Resumen de Suite de Pruebas

| Categor√≠a | Pruebas | Aprobadas | Cobertura |
|-----------|---------|-----------|-----------|
| Contratos | 45 | 45 | 92% |
| Se√±ales | 33 | 33 | 95% |
| Ingesta CPP | 16 | 16 | 88% |
| ArgRouter | 24 | 24 | 100% |
| Integraci√≥n | 18 | 18 | N/A |
| **TOTAL** | **238** | **238** | **87.3%** |

### Ejecutar Pruebas

```bash
# Suite completa de pruebas
python -m pytest tests/ -v --cov=src/saaaaaa --cov-report=term-missing

# Categor√≠as espec√≠ficas de pruebas
python -m pytest tests/test_contracts.py -v
python -m pytest tests/test_signals.py -v
python -m pytest tests/test_cpp_ingestion.py -v

# Golden tests (determinismo)
python -m pytest tests/test_regression_*.py -v
```

### Ejecuci√≥n del Plan de Pruebas

Ver [TEST_PLAN.md](TEST_PLAN.md) para casos de prueba completos.

**Validaci√≥n r√°pida**:
```bash
# Ejecutar todas las pruebas requeridas
bash test_suite.sh
```

---

## üî¨ Temas Avanzados

### Sistema de Calibraci√≥n

El sistema de calibraci√≥n gestiona par√°metros de puntuaci√≥n en las 300 preguntas.

**Configuraci√≥n**:
- `config/intrinsic_calibration.json` - Par√°metros base de calibraci√≥n
- `config/fusion_specification.json` - Reglas de fusi√≥n multi-m√©todo
- `config/layer_calibrations/` - Calibraciones espec√≠ficas por capa

**Documentaci√≥n**: [docs/CALIBRATION_QUICK_START.md](docs/CALIBRATION_QUICK_START.md)

### Irrigaci√≥n de Se√±ales

Sistema de se√±ales transversales que propaga patrones del cuestionario a todos los ejecutores.

**Archivos Clave**:
- `src/saaaaaa/core/orchestrator/signals.py` - Cliente/registro de se√±ales
- `src/saaaaaa/core/orchestrator/signal_loader.py` - Extracci√≥n de patrones

**Documentaci√≥n**: [docs/SIGNAL_IRRIGATION_README.md](docs/SIGNAL_IRRIGATION_README.md)

### Especificaci√≥n de Contratos V3

√öltimo formato de contrato de ejecutor con estructura completa.

**Esquema**: `config/schemas/executor_contract.v3.schema.json`

**Documentaci√≥n**: [docs/contracts/README.md](docs/contracts/README.md)

### Sistema de Importaci√≥n

Sistema de importaci√≥n determinista, auditable y portable con importaciones seguras y carga perezosa.

**Documentaci√≥n**: [docs/IMPORT_SYSTEM.md](docs/IMPORT_SYSTEM.md)

### Rastreo de Proveniencia

Trazabilidad completa token-a-fuente v√≠a Arrow IPC.

**C√°lculo**:
```python
def _calculate_provenance_completeness(chunks: List[Chunk]) -> float:
    total_tokens = sum(len(c.text.split()) for c in chunks)
    tokens_with_prov = sum(
        len(c.text.split()) for c in chunks if c.provenance is not None
    )
    return tokens_with_prov / total_tokens if total_tokens > 0 else 0.0
```

---

## üõ†Ô∏è Desarrollo

### Configurar Entorno de Desarrollo

```bash
# Clonar e instalar
git clone https://github.com/PEROPOROBTANTE/F.A.R.F.A.N-MECHANISTIC_POLICY_PIPELINE_FINAL.git
cd F.A.R.F.A.N-MECHANISTIC_POLICY_PIPELINE_FINAL
bash install.sh
source farfan-env/bin/activate

# Instalar dependencias de desarrollo
pip install -r requirements-dev.txt

# Verificar instalaci√≥n
python -m saaaaaa.devtools.ensure_install
```

### Estructura del C√≥digo

```
src/saaaaaa/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/          # Motor principal de orquestaci√≥n (30+ m√≥dulos)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core.py            # Orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executors.py       # Implementaciones de ejecutores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arg_router.py      # Enrutador extendido de argumentos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ questionnaire.py   # Integridad del cuestionario
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ signals.py         # Sistema de se√±ales
‚îÇ   ‚îî‚îÄ‚îÄ phases/                # Definiciones de fases
‚îú‚îÄ‚îÄ processing/
‚îÇ   ‚îú‚îÄ‚îÄ spc_ingestion/         # Capa de conversi√≥n SPC
‚îÇ   ‚îî‚îÄ‚îÄ [procesadores]         # Procesadores de documentos
‚îú‚îÄ‚îÄ analysis/                  # M√≥dulos de an√°lisis
‚îî‚îÄ‚îÄ utils/                     # Utilidades y adaptadores
```

### Agregar Nuevos Analizadores

1. Crear clase analizadora en `src/saaaaaa/analysis/`
2. Registrar en `src/saaaaaa/core/orchestrator/class_registry.py`
3. Agregar firma de m√©todo al cat√°logo can√≥nico de m√©todos
4. Crear contrato de ejecutor en `config/executor_contracts/`
5. Agregar pruebas en `tests/`

### Consejos de Depuraci√≥n

```bash
# Habilitar modo debug
export PIPELINE_DEBUG=1

# Ejecutar con salida verbose
python scripts/run_policy_pipeline_verified.py \
    --plan data/plans/Plan_1.pdf \
    --artifacts-dir artifacts/debug \
    2>&1 | tee debug.log

# Analizar claims de ejecuci√≥n
jq '.[] | select(.claim_type=="error")' artifacts/debug/execution_claims.json
```

---

## üêõ Soluci√≥n de Problemas

### Problemas Comunes

#### Problema 1: Errores de Importaci√≥n

**S√≠ntomas**:
```
ImportError: cannot import name 'TorchTensorParallelPlugin'
ModuleNotFoundError: No module named 'transformers'
```

**Soluci√≥n**:
```bash
# Verificar versiones correctas
pip list | grep -E "transformers|accelerate|sentence-transformers"

# Deber√≠a mostrar:
# transformers==4.41.2
# accelerate==1.2.1
# sentence-transformers==3.1.0

# Reinstalar si es necesario
bash install.sh
```

#### Problema 2: Discrepancia de Hash del Cuestionario

**S√≠ntomas**:
```
HashValidationError: Discrepancia de hash del cuestionario
```

**Soluci√≥n**:
```bash
# Verificar si el archivo fue modificado
git status data/questionnaire_monolith.json

# Revertir a versi√≥n can√≥nica
git checkout data/questionnaire_monolith.json

# Verificar integridad
python3 -c "
from saaaaaa.core.orchestrator.questionnaire import load_questionnaire
q = load_questionnaire()
print(f'‚úì Hash verificado: {q.sha256[:16]}...')
"
```

#### Problema 3: Falta de Memoria

**S√≠ntomas**:
```
MemoryError: No se puede asignar array
Killed
```

**Soluci√≥n**:
```bash
# Reducir conteo de chunks (editar scripts de pipeline)
# Cambiar max_chunks=50 a max_chunks=25

# O aumentar memoria disponible
# M√≠nimo: 8GB RAM
# Recomendado: 16GB RAM
```

#### Problema 4: Pipeline se Cuelga

**S√≠ntomas**:
- Pipeline ejecuta > 10 minutos sin salida
- Uso de CPU cae a 0%

**Soluci√≥n**:
```bash
# Matar pipeline
pkill -f "python.*run_policy"

# Reiniciar con modo debug
export PIPELINE_DEBUG=1
python scripts/run_policy_pipeline_verified.py \
    --plan data/plans/Plan_1.pdf \
    --artifacts-dir artifacts/debug
```

### Obtener Ayuda

**Si los problemas persisten**:

1. Verificar versi√≥n de Python: `python3.12 --version` (debe ser 3.12.x)
2. Ejecutar diagn√≥stico: `python diagnose_import_error.py`
3. Revisar logs: Revisar salida de ejecuci√≥n del pipeline
4. Verificar rama git: `git branch`

**Soporte**:
- GitHub Issues: https://github.com/PEROPOROBTANTE/F.A.R.F.A.N-MECHANISTIC_POLICY_PIPELINE_FINAL/issues
- Incluir salida de: `python diagnose_import_error.py`

---

## ü§ù Contribuir

Ver [CONTRIBUTING.md](CONTRIBUTING.md) para gu√≠as de contribuci√≥n.

**Flujo r√°pido de contribuci√≥n**:
1. Fork del repositorio
2. Crear rama de caracter√≠stica (`git checkout -b feature/caracteristica-increible`)
3. Hacer cambios y agregar pruebas
4. Ejecutar suite de pruebas (`bash test_suite.sh`)
5. Commit de cambios (`git commit -m 'Agregar caracter√≠stica incre√≠ble'`)
6. Push a rama (`git push origin feature/caracteristica-increible`)
7. Abrir Pull Request

---

## üìÑ Licencia y Citaci√≥n

### Licencia

Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

### Citaci√≥n

Si usa F.A.R.F.A.N en su investigaci√≥n, por favor cite:

```bibtex
@software{farfan2025,
  title={F.A.R.F.A.N: Framework for Advanced Retrieval of Administrative Narratives},
  author={Equipo de Desarrollo F.A.R.F.A.N},
  year={2025},
  url={https://github.com/PEROPOROBTANTE/F.A.R.F.A.N-MECHANISTIC_POLICY_PIPELINE_FINAL},
  version={1.0.0}
}
```

---

## üìñ Recursos Adicionales

- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Arquitectura detallada del sistema
- **[RUNBOOK.md](RUNBOOK.md)** - Manual operacional
- **[TEST_PLAN.md](TEST_PLAN.md)** - Plan de pruebas completo
- **[CHANGELOG.md](CHANGELOG.md)** - Historial de versiones
- **[docs/](docs/)** - Documentaci√≥n extendida

---

**Versi√≥n**: 1.0.0  
**√öltima Actualizaci√≥n**: 2025-11-26  
**Estado**: Listo para Producci√≥n
